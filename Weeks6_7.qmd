---
title: "Weeks 6 & 7: Building a corpus from media platforms"
format: 
  html:
    output-file: Weeks6_7.html
    number-sections: true
    number-depth: 2
    toc: true
---

```{=html}
<style>
hr.rounded {
  border-top: 1px solid #E5E4E2;
  border-radius: 5px;
}
</style>
```

<br>

::: {.callout-warning icon="false"}
## Objectives

These two weeks, you will learn how to use R to build a corpus from online Taiwanese newspapers.
:::

# Building your own corpus: Conceptual and technical considerations

There are many tools that we can use now to build a corpus based on data coming from the Internet, and this includes R packages. But many concepts need to be clarified before getting into the coding part, such as:

-   Being aware of the *steps* you are going through if you had to manually copy and paste the data you want into an Excel file, and document each step with as many details as possible,

-   Understanding the *structure* of a website, how to *access* the structure of the website, and how to *localize* where the information you want are,

-   Finally, *mapping* the R functions to the information you want.

These are the steps we will be going through these two weeks. We will work with one Taiwanese newspaper called "ETtoday" (<https://www.ettoday.net/>). We will particularly work based on this link which references all the articles since 2011: <https://www.ettoday.net/news/news-list.htm>.

![](assets/images/ETtoday_logo.png)

::: {.callout-warning icon="false"}
## More about ETtoday (source: Wikipedia)

ETtoday is one of the main newspapers in Taiwan. It has been officially founded in 2011, and it publishes numerous articles on many topics online everyday. Some may say that it is not politically neutral, so it is something to keep in mind as this may affect the results depending on your research question.
:::

# Document your own manual steps

## What is the task

First, you need to be very clear about what you want to do, otherwise you can literally spend hours doing a lot of things but actually achieving nothing.

So here is your first task:

1.  Go on the ETtoday website, and search for one article.

2.  Describe each step and action you are doing to get into one article, and document the changes that happen regarding **the address of the website**.

## Documentation of the manual steps

This task is seems quite easy, but it is crucial. First, you went to the website by clicking on the link. Then, you selected the date of the news you were interested in. Third, you selected the type of news (politics, society, etc.). A list of articles was already there on the website, and you were just filtering them. And to get into one article, you just clicked on one of the title below the search bar. 

```{r setup, include = FALSE}
library(DiagrammeR)
```

```{r mermaid-example, echo=FALSE}
    mermaid("
    graph TD
        A[ETtoday website with list of articles] -- Select date --> B{Filtered articles};
        A -- Select type --> B{Filtered articles};
        B --> C[Click on the title of one article];
        C --> D[New webpage: Individual article]
    ")
```
