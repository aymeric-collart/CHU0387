---
title: "Weeks 6 & 7: Building a corpus from media platforms"
format: 
  html:
    output-file: Weeks6_7.html
    number-sections: true
    number-depth: 2
    toc: true
---

```{=html}
<style>
hr.rounded {
  border-top: 1px solid #E5E4E2;
  border-radius: 5px;
}
</style>
```

<br>

::: {.callout-warning icon="false"}
## Objectives

These two weeks, you will learn how to use R to build a corpus from online Taiwanese newspapers.
:::

# Building your own corpus: Conceptual and technical considerations

There are many tools that we can use now to build a corpus based on data coming from the Internet, and this includes R packages. But many concepts need to be clarified before getting into the coding part, such as:

-   Being aware of the *steps* you are going through if you had to manually copy and paste the data you want into an Excel file, and document each step with as many details as possible,

-   Understanding the *structure* of a website, how to *access* the structure of the website, and how to *localize* where the information you want are,

-   Finally, *mapping* the R functions to the information you want.

These are the steps we will be going through these two weeks. We will work with one Taiwanese newspaper called "ETtoday" (<https://www.ettoday.net/>). We will particularly work based on this link which references all the articles since 2011: <https://www.ettoday.net/news/news-list.htm>.

![](assets/images/ETtoday_logo.png)

::: {.callout-warning icon="false"}
## More about ETtoday (source: Wikipedia)

ETtoday is one of the main newspapers in Taiwan. It has been officially founded in 2011, and it publishes numerous articles on many topics online everyday. Some may say that it is not politically neutral, so it is something to keep in mind as this may affect the results depending on your research question.
:::

# Document your own manual steps

## What is the task

First, you need to be very clear about what you want to do, otherwise you can literally spend hours doing a lot of things but actually achieving nothing.

So here is your first task:

1.  Go on the ETtoday website, and search for one article.

2.  Describe each step and action you are doing to get into one article, and document the changes that happen regarding **the address of the website**.

## Documentation of the manual steps

This task is seems quite easy, but it is crucial. First, you went to the website by clicking on the link. Then, you selected the date of the news you were interested in. Third, you selected the type of news (politics, society, etc.). A list of articles was already there on the website, and you were just filtering them. And to get into one article, you just clicked on one of the title below the search bar.

This procedure looks like this:

```{r setup, include = FALSE}
library(DiagrammeR)
```

```{r mermaid-example, echo=FALSE, fig.align='center'}
    mermaid("
    graph TD
        A[ETtoday website with list of articles] -- Select date --> B{Filtered articles};
        A -- Select type --> B{Filtered articles};
        B --> C[Click on the title of one article];
        C --> D[New webpage: Individual article]
    ")
```

Now we will do the same, but pay more attention to **the web address**, and track the changes that occur. For instance, the first step is just accessing the website. The web address is "<https://www.ettoday.net/news/news-list.htm>". What is the web address when you select a particular date, let's say October 28th, 2024? And when you select a particular type of article, "politics" for example? And finally, when you choose an individual article?

Here is what we get:

-   First step: <https://www.ettoday.net/news/news-list.htm>

-   Second step (filtered articles): <https://www.ettoday.net/news/news-list-2024-10-28-1.htm>

-   Third step: (individual article): <https://www.ettoday.net/news/20241028/2843953.htm>

::: callout-tip
## Think about it

-   First, we can see that filtering the data changes the address of the website in a very systematic way. Now, try to change the address to access the list of articles published on September 27th, 2024. You will get something like that: <https://www.ettoday.net/news/news-list-2024-09-27-1.htm>
-   Second, try to change the last number. You will see that it changes the type of articles.

**So this means that you can filter the list of articles as you wish just by changing the web address!**

-   Third, if we look at the web address of the individual article, we can retrieve the date of publication of the article very easily... but it is not quite possible to guess the numbers after that.
:::

No need to despair! The fact that this article is found in the list means that ***the web address of the individual article*** must be somewhere on the website... but where? This is the moment when it is important to **understand the structure of the website**.

# Understanding the structure of the website

## How to access the structure of the website?

Accessing to the structure of a website is actually very easy. You just need to open the webpage, for example this one: <https://www.ettoday.net/news/news-list-2024-10-28-1.htm>. Then, you look for a blank space, you right-click, and you select "View Page Source" (it is possible that it will not be in English, or that the wording is different depending on the system of your computer).

Then, it will open a new page which can be very scary... but this is actually the same, just the structure of the previous page!

Here is the animated figure of these steps:

![](assets/images/ETtoday_ListArticles_Structure.gif)
